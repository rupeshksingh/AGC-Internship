{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1137b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e41b9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly_range_ml(df, speed_col='speed', label_col='pred_label',\n",
    "                            timestamp_col='indo_time', test_size=0.3, random_state=42,\n",
    "                            save_path='anomaly_range_plot.png'\n",
    "                            ):\n",
    "\n",
    "    features = pd.DataFrame(df[speed_col])\n",
    "    features.columns = ['Speed']\n",
    "\n",
    "    window_short = 60\n",
    "    window_medium = 300\n",
    "    window_long = 900\n",
    "\n",
    "    # Rolling features for different time scales\n",
    "    features[f'Speed_rolling_mean_{window_short}'] = df[speed_col].rolling(window=window_short, min_periods=1).mean()\n",
    "    features[f'Speed_rolling_std_{window_short}'] = df[speed_col].rolling(window=window_short, min_periods=1).std().fillna(0)\n",
    "\n",
    "    features[f'Speed_rolling_mean_{window_medium}'] = df[speed_col].rolling(window=window_medium, min_periods=int(window_medium * 0.2)).mean() # min_periods 20% of window\n",
    "    features[f'Speed_rolling_std_{window_medium}'] = df[speed_col].rolling(window=window_medium, min_periods=int(window_medium * 0.2)).std().fillna(0)\n",
    "\n",
    "    features[f'Speed_rolling_mean_{window_long}'] = df[speed_col].rolling(window=window_long, min_periods=int(window_long * 0.2)).mean() # min_periods 20% of window\n",
    "    features[f'Speed_rolling_std_{window_long}'] = df[speed_col].rolling(window=window_long, min_periods=int(window_long * 0.2)).std().fillna(0)\n",
    "\n",
    "    # 1. Temporal Transition Features\n",
    "    features['Speed_diff_1'] = df[speed_col].diff(periods=1).fillna(0)\n",
    "    features['Speed_diff_5'] = df[speed_col].diff(periods=5).fillna(0) # Change over 5 seconds\n",
    "    features['Speed_acceleration'] = df[speed_col].diff(periods=1).diff(periods=1).fillna(0)\n",
    "\n",
    "    # 2. Contextual Window Features (Rolling Z-Score and Window Discrepancy)\n",
    "    features[f'Speed_rolling_zscore_{window_short}'] = (df[speed_col] - features[f'Speed_rolling_mean_{window_short}']) / (features[f'Speed_rolling_std_{window_short}'] + 1e-9)\n",
    "    features[f'Speed_rolling_zscore_{window_medium}'] = (df[speed_col] - features[f'Speed_rolling_mean_{window_medium}']) / (features[f'Speed_rolling_std_{window_medium}'] + 1e-9)\n",
    "    features[f'Speed_rolling_zscore_{window_long}'] = (df[speed_col] - features[f'Speed_rolling_mean_{window_long}']) / (features[f'Speed_rolling_std_{window_long}'] + 1e-9)\n",
    "\n",
    "    features[f'Speed_rolling_median_{window_short}'] = df[speed_col].rolling(window=window_short, min_periods=1).median()\n",
    "    features[f'Speed_mean_median_diff_{window_short}'] = features[f'Speed_rolling_mean_{window_short}'] - features[f'Speed_rolling_median_{window_short}']\n",
    "\n",
    "    features[f'Speed_rolling_median_{window_medium}'] = df[speed_col].rolling(window=window_medium, min_periods=int(window_medium * 0.2)).median()\n",
    "    features[f'Speed_mean_median_diff_{window_medium}'] = features[f'Speed_rolling_mean_{window_medium}'] - features[f'Speed_rolling_median_{window_medium}']\n",
    "\n",
    "    features[f'Speed_rolling_median_{window_long}'] = df[speed_col].rolling(window=window_long, min_periods=int(window_long * 0.2)).median()\n",
    "    features[f'Speed_mean_median_diff_{window_long}'] = features[f'Speed_rolling_mean_{window_long}'] - features[f'Speed_rolling_median_{window_long}']\n",
    "\n",
    "    # 3. Anomaly Persistence Metrics (Simplified CUSUM of Positive Deviations)\n",
    "    features[f'Speed_positive_deviation_{window_short}'] = np.maximum(0, df[speed_col] - features[f'Speed_rolling_mean_{window_short}'])\n",
    "    features[f'Speed_cusum_positive_{window_short}'] = features[f'Speed_positive_deviation_{window_short}'].cumsum()\n",
    "\n",
    "    features[f'Speed_positive_deviation_{window_medium}'] = np.maximum(0, df[speed_col] - features[f'Speed_rolling_mean_{window_medium}'])\n",
    "    features[f'Speed_cusum_positive_{window_medium}'] = features[f'Speed_positive_deviation_{window_medium}'].cumsum()\n",
    "\n",
    "    # 4. Additional Rolling Statistics\n",
    "    features[f'Speed_rolling_min_{window_short}'] = df[speed_col].rolling(window=window_short, min_periods=1).min()\n",
    "    features[f'Speed_rolling_max_{window_short}'] = df[speed_col].rolling(window=window_short, min_periods=1).max()\n",
    "    features[f'Speed_rolling_q25_{window_short}'] = df[speed_col].rolling(window=window_short, min_periods=1).quantile(0.25)\n",
    "    features[f'Speed_rolling_q75_{window_short}'] = df[speed_col].rolling(window=window_short, min_periods=1).quantile(0.75)\n",
    "\n",
    "    features[f'Speed_rolling_min_{window_medium}'] = df[speed_col].rolling(window=window_medium, min_periods=int(window_medium * 0.2)).min()\n",
    "    features[f'Speed_rolling_max_{window_medium}'] = df[speed_col].rolling(window=window_medium, min_periods=int(window_medium * 0.2)).max()\n",
    "    features[f'Speed_rolling_q25_{window_medium}'] = df[speed_col].rolling(window=window_medium, min_periods=int(window_medium * 0.2)).quantile(0.25)\n",
    "    features[f'Speed_rolling_q75_{window_medium}'] = df[speed_col].rolling(window=window_medium, min_periods=int(window_medium * 0.2)).quantile(0.75)\n",
    "\n",
    "    # 5. Exponentially Weighted Moving Average (EWMA)\n",
    "    features['Speed_ewm_mean_alpha_0.1'] = df[speed_col].ewm(span=10, adjust=False, min_periods=1).mean()\n",
    "    features['Speed_ewm_std_alpha_0.1'] = df[speed_col].ewm(span=10, adjust=False, min_periods=1).std().fillna(0)\n",
    "\n",
    "    # 6. Lagged Features\n",
    "    features['Speed_lag_1'] = df[speed_col].shift(1).fillna(0)\n",
    "    features['Speed_lag_5'] = df[speed_col].shift(5).fillna(0)\n",
    "    features['Speed_lag_60'] = df[speed_col].shift(60).fillna(0) # Lag by 1 minute\n",
    "\n",
    "    X = features\n",
    "    y = df[label_col]\n",
    "\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "    print(f\"Training data shape: {X_train.shape}\")\n",
    "    print(f\"Testing data shape: {X_test.shape}\")\n",
    "    print(f\"Anomaly distribution in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
    "    print(f\"Anomaly distribution in test set:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "    neg_count = y_train.value_counts().get(0, 0)\n",
    "    pos_count = y_train.value_counts().get(1, 0)\n",
    "    scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1\n",
    "\n",
    "    print(\"\\nTraining XGBClassifier...\")\n",
    "    model = XGBClassifier(n_estimators=100, random_state=random_state, use_label_encoder=False,\n",
    "                          eval_metric='logloss', scale_pos_weight=scale_pos_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"\\n--- Model Evaluation Metrics on Test Data ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred):.4f}\")\n",
    "    try:\n",
    "        print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "    except ValueError:\n",
    "        print(\"ROC AUC Score: Not applicable (only one class present in y_test or y_pred_proba).\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\n--- Feature Importances (XGBoost) ---\")\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    print(feature_importances.to_string(index=False))\n",
    "\n",
    "    # Full‚Äêdata prediction\n",
    "    y_full_pred = model.predict(X)\n",
    "\n",
    "    intervals_idx = []\n",
    "    in_anomaly = False\n",
    "    start_idx = None\n",
    "\n",
    "    for i, lab in enumerate(y_full_pred):\n",
    "        if lab == 1 and not in_anomaly:\n",
    "            in_anomaly = True\n",
    "            start_idx = i\n",
    "        elif lab == 0 and in_anomaly:\n",
    "            intervals_idx.append((start_idx, i - 1))\n",
    "            in_anomaly = False\n",
    "\n",
    "    if in_anomaly:\n",
    "        intervals_idx.append((start_idx, len(y_full_pred) - 1))\n",
    "\n",
    "    if not intervals_idx:\n",
    "        print(\"No predicted anomaly intervals (model output == 1).\")\n",
    "        return []\n",
    "\n",
    "    intervals_ts = []\n",
    "    for (s_idx, e_idx) in intervals_idx:\n",
    "        s_ts = df.loc[s_idx, timestamp_col]\n",
    "        e_ts = df.loc[e_idx, timestamp_col]\n",
    "        intervals_ts.append((s_ts, e_ts))\n",
    "\n",
    "        context_window = 60\n",
    "\n",
    "    for i, (s_idx, e_idx) in enumerate(intervals_idx[:5]):\n",
    "        start_context = max(0, s_idx - context_window)\n",
    "        end_context = min(len(df) - 1, e_idx + context_window)\n",
    "\n",
    "        df_seg = df.loc[start_context:end_context].copy()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        sc = plt.scatter(\n",
    "            df_seg[timestamp_col],\n",
    "            df_seg[speed_col],\n",
    "            c=df_seg[label_col],\n",
    "            cmap='coolwarm',\n",
    "            s=15,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "\n",
    "        s_ts = df.loc[s_idx, timestamp_col]\n",
    "        e_ts = df.loc[e_idx, timestamp_col]\n",
    "\n",
    "        plt.axvline(x=s_ts, color='green', linestyle='--', linewidth=1.2, label='Anomaly Start')\n",
    "        plt.axvline(x=e_ts, color='red', linestyle='--', linewidth=1.2, label='Anomaly End')\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Speed')\n",
    "        plt.title(f'Interval {i+1}: {s_ts} ‚Üí {e_ts}')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"anomaly_interval_{i+1}.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot: {filename}\")\n",
    "\n",
    "\n",
    "    return intervals_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df31c478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (70000, 36)\n",
      "Testing data shape: (30000, 36)\n",
      "Anomaly distribution in training set:\n",
      "pred_label\n",
      "0    0.956943\n",
      "1    0.043057\n",
      "Name: proportion, dtype: float64\n",
      "Anomaly distribution in test set:\n",
      "pred_label\n",
      "0    0.956967\n",
      "1    0.043033\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training XGBClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rupesh Kumar singh\\OneDrive\\Desktop\\Work\\AGC Work\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:25:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "\n",
      "--- Model Evaluation Metrics on Test Data ---\n",
      "Accuracy: 0.9999\n",
      "Balanced Accuracy: 0.9988\n",
      "ROC AUC Score: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28709\n",
      "           1       1.00      1.00      1.00      1291\n",
      "\n",
      "    accuracy                           1.00     30000\n",
      "   macro avg       1.00      1.00      1.00     30000\n",
      "weighted avg       1.00      1.00      1.00     30000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[28708     1]\n",
      " [    3  1288]]\n",
      "\n",
      "--- Feature Importances (XGBoost) ---\n",
      "                     Feature  Importance\n",
      "       Speed_rolling_std_300    0.576651\n",
      "    Speed_ewm_mean_alpha_0.1    0.117772\n",
      "        Speed_rolling_min_60    0.056618\n",
      "    Speed_rolling_median_300    0.050634\n",
      "       Speed_rolling_min_300    0.041285\n",
      "  Speed_mean_median_diff_300    0.033804\n",
      "        Speed_rolling_std_60    0.019560\n",
      "        Speed_rolling_q25_60    0.015761\n",
      "      Speed_rolling_mean_900    0.015355\n",
      "       Speed_rolling_q75_300    0.010664\n",
      "       Speed_rolling_std_900    0.007588\n",
      "     Speed_ewm_std_alpha_0.1    0.007080\n",
      "        Speed_rolling_q75_60    0.006045\n",
      "      Speed_rolling_mean_300    0.004768\n",
      "          Speed_acceleration    0.004477\n",
      "                Speed_diff_1    0.004199\n",
      "     Speed_cusum_positive_60    0.003756\n",
      "       Speed_rolling_mean_60    0.002280\n",
      "       Speed_rolling_q25_300    0.002152\n",
      "    Speed_cusum_positive_300    0.002115\n",
      "     Speed_rolling_zscore_60    0.002039\n",
      "    Speed_rolling_zscore_300    0.001871\n",
      " Speed_positive_deviation_60    0.001724\n",
      "                 Speed_lag_1    0.001696\n",
      "       Speed_rolling_max_300    0.001644\n",
      "   Speed_mean_median_diff_60    0.001425\n",
      "    Speed_rolling_zscore_900    0.001398\n",
      "                       Speed    0.001242\n",
      "        Speed_rolling_max_60    0.000989\n",
      "  Speed_mean_median_diff_900    0.000903\n",
      "                 Speed_lag_5    0.000737\n",
      "     Speed_rolling_median_60    0.000625\n",
      "                Speed_diff_5    0.000478\n",
      "    Speed_rolling_median_900    0.000385\n",
      "                Speed_lag_60    0.000222\n",
      "Speed_positive_deviation_300    0.000058\n",
      "Saved plot: anomaly_interval_1.png\n",
      "Saved plot: anomaly_interval_2.png\n",
      "Saved plot: anomaly_interval_3.png\n",
      "Saved plot: anomaly_interval_4.png\n",
      "Saved plot: anomaly_interval_5.png\n",
      "\n",
      "Final Result: Found 14 anomaly ranges.\n"
     ]
    }
   ],
   "source": [
    "file_path = 'AGC_Data.csv'\n",
    "\n",
    "try:\n",
    "    data_df = pd.read_csv(file_path, parse_dates=['indo_time'])\n",
    "    intervals_ts = detect_anomaly_range_ml(df=data_df, speed_col='speed', label_col='pred_label', timestamp_col='indo_time')\n",
    "\n",
    "    if intervals_ts:\n",
    "        print(f\"\\nFinal Result: Found {len(intervals_ts)} anomaly ranges.\")\n",
    "    else:\n",
    "        print(\"\\nFinal Result: No anomaly range found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "136e41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly_range_ml(\n",
    "    df,\n",
    "    speed_col='speed',\n",
    "    label_col='pred_label',\n",
    "    timestamp_col='indo_time',\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    save_path_prefix='anomaly_interval'\n",
    "):\n",
    "    features = pd.DataFrame(df[speed_col]).copy()\n",
    "    features.columns = ['Speed']\n",
    "\n",
    "    window_short = 60\n",
    "    window_medium = 300\n",
    "    window_long = 900\n",
    "\n",
    "    # Rolling‚Äêwindow means and stds\n",
    "    features[f'Speed_rolling_mean_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "    features[f'Speed_rolling_std_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_mean_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .mean()\n",
    "    )\n",
    "    features[f'Speed_rolling_std_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_mean_{window_long}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_long, min_periods=int(window_long * 0.2))\n",
    "        .mean()\n",
    "    )\n",
    "    features[f'Speed_rolling_std_{window_long}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_long, min_periods=int(window_long * 0.2))\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # Temporal‚Äêtransition differences\n",
    "    features['Speed_diff_1'] = df[speed_col].diff(periods=1).fillna(0)\n",
    "    features['Speed_diff_5'] = df[speed_col].diff(periods=5).fillna(0)\n",
    "    features['Speed_acceleration'] = df[speed_col].diff(periods=1).diff(periods=1).fillna(0)\n",
    "\n",
    "    # Rolling‚Äêwindow z‚Äêscores\n",
    "    features[f'Speed_rolling_zscore_{window_short}'] = (\n",
    "        (df[speed_col] - features[f'Speed_rolling_mean_{window_short}']) /\n",
    "        (features[f'Speed_rolling_std_{window_short}'] + 1e-9)\n",
    "    )\n",
    "    features[f'Speed_rolling_zscore_{window_medium}'] = (\n",
    "        (df[speed_col] - features[f'Speed_rolling_mean_{window_medium}']) /\n",
    "        (features[f'Speed_rolling_std_{window_medium}'] + 1e-9)\n",
    "    )\n",
    "    features[f'Speed_rolling_zscore_{window_long}'] = (\n",
    "        (df[speed_col] - features[f'Speed_rolling_mean_{window_long}']) /\n",
    "        (features[f'Speed_rolling_std_{window_long}'] + 1e-9)\n",
    "    )\n",
    "\n",
    "    # Rolling medians and mean‚Äêmedian differences\n",
    "    features[f'Speed_rolling_median_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .median()\n",
    "    )\n",
    "    features[f'Speed_mean_median_diff_{window_short}'] = (\n",
    "        features[f'Speed_rolling_mean_{window_short}'] -\n",
    "        features[f'Speed_rolling_median_{window_short}']\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_median_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .median()\n",
    "    )\n",
    "    features[f'Speed_mean_median_diff_{window_medium}'] = (\n",
    "        features[f'Speed_rolling_mean_{window_medium}'] -\n",
    "        features[f'Speed_rolling_median_{window_medium}']\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_median_{window_long}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_long, min_periods=int(window_long * 0.2))\n",
    "        .median()\n",
    "    )\n",
    "    features[f'Speed_mean_median_diff_{window_long}'] = (\n",
    "        features[f'Speed_rolling_mean_{window_long}'] -\n",
    "        features[f'Speed_rolling_median_{window_long}']\n",
    "    )\n",
    "\n",
    "    # CUSUM of positive deviations (persistence metrics)\n",
    "    features[f'Speed_positive_deviation_{window_short}'] = np.maximum(\n",
    "        0, df[speed_col] - features[f'Speed_rolling_mean_{window_short}']\n",
    "    )\n",
    "    features[f'Speed_cusum_positive_{window_short}'] = (\n",
    "        features[f'Speed_positive_deviation_{window_short}'].cumsum()\n",
    "    )\n",
    "\n",
    "    features[f'Speed_positive_deviation_{window_medium}'] = np.maximum(\n",
    "        0, df[speed_col] - features[f'Speed_rolling_mean_{window_medium}']\n",
    "    )\n",
    "    features[f'Speed_cusum_positive_{window_medium}'] = (\n",
    "        features[f'Speed_positive_deviation_{window_medium}'].cumsum()\n",
    "    )\n",
    "\n",
    "    # Additional rolling statistics (min, max, quartiles)\n",
    "    features[f'Speed_rolling_min_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .min()\n",
    "    )\n",
    "    features[f'Speed_rolling_max_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .max()\n",
    "    )\n",
    "    features[f'Speed_rolling_q25_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .quantile(0.25)\n",
    "    )\n",
    "    features[f'Speed_rolling_q75_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .quantile(0.75)\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_min_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .min()\n",
    "    )\n",
    "    features[f'Speed_rolling_max_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .max()\n",
    "    )\n",
    "    features[f'Speed_rolling_q25_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .quantile(0.25)\n",
    "    )\n",
    "    features[f'Speed_rolling_q75_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .quantile(0.75)\n",
    "    )\n",
    "\n",
    "    # EWMA (alpha=0.1)\n",
    "    features['Speed_ewm_mean_alpha_0.1'] = (\n",
    "        df[speed_col]\n",
    "        .ewm(span=60, adjust=False, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "    features['Speed_ewm_std_alpha_0.1'] = (\n",
    "        df[speed_col]\n",
    "        .ewm(span=60, adjust=False, min_periods=1)\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # Lagged features\n",
    "    features['Speed_lag_1'] = df[speed_col].shift(1).fillna(0)\n",
    "    features['Speed_lag_60'] = df[speed_col].shift(60).fillna(0)\n",
    "    features['Speed_lag_3600'] = df[speed_col].shift(3600).fillna(0)\n",
    "\n",
    "\n",
    "    X = features.fillna(features.mean())\n",
    "    y = df[label_col]\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=test_size,\n",
    "        stratify=y,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    val_fraction_within = test_size / (1 - test_size)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        test_size=val_fraction_within,\n",
    "        stratify=y_train_val,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"Train shape: {X_train.shape}\")\n",
    "    print(f\"Validation shape: {X_val.shape}\")\n",
    "    print(f\"Test shape: {X_test.shape}\\n\")\n",
    "\n",
    "    print(\"Anomaly distribution in training set:\")\n",
    "    print(y_train.value_counts(normalize=True))\n",
    "    print(\"\\nAnomaly distribution in validation set:\")\n",
    "    print(y_val.value_counts(normalize=True))\n",
    "    print(\"\\nAnomaly distribution in test set:\")\n",
    "    print(y_test.value_counts(normalize=True))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    neg_count = y_train.value_counts().get(0, 0)\n",
    "    pos_count = y_train.value_counts().get(1, 0)\n",
    "    scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1\n",
    "\n",
    "    # ======== Train XGBClassifier on Training Split ========\n",
    "    print(\"Training XGBClassifier on TRAIN split...\")\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=random_state,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_pos_weight\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Training complete.\\n\")\n",
    "\n",
    "    # ======== Evaluate on Validation Split ========\n",
    "    print(\"--- MODEL EVALUATION ON VALIDATION SPLIT ---\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    print(f\"Accuracy (Val): {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "    print(f\"Balanced Accuracy (Val): {balanced_accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "    try:\n",
    "        print(f\"ROC AUC (Val): {roc_auc_score(y_val, y_val_proba):.4f}\")\n",
    "    except ValueError:\n",
    "        print(\"ROC AUC (Val): N/A (only one class present).\")\n",
    "\n",
    "    print(\"\\nClassification Report (Val):\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"Confusion Matrix (Val):\")\n",
    "    print(confusion_matrix(y_val, y_val_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Show feature importances\n",
    "    print(\"--- FEATURE IMPORTANCES (XGBoost) ---\")\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    print(feature_importances.to_string(index=False))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # ======== Predict & Plot on Test Split ========\n",
    "    print(\"Predicting on TEST split and plotting anomaly intervals...\")\n",
    "    test_indices = X_test.index.values\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    intervals_idx = []\n",
    "    in_anomaly = False\n",
    "    start_idx = None\n",
    "\n",
    "    for orig_i, pred_label in zip(test_indices, y_test_pred):\n",
    "        if (pred_label == 1) and (not in_anomaly):\n",
    "            in_anomaly = True\n",
    "            start_idx = orig_i\n",
    "        elif (pred_label == 0) and in_anomaly:\n",
    "            intervals_idx.append((start_idx, prev_i))\n",
    "            in_anomaly = False\n",
    "\n",
    "        prev_i = orig_i\n",
    "\n",
    "    if in_anomaly:\n",
    "        intervals_idx.append((start_idx, prev_i))\n",
    "\n",
    "    if not intervals_idx:\n",
    "        print(\"No predicted anomaly intervals in TEST split.\")\n",
    "        return []\n",
    "\n",
    "    intervals_ts = []\n",
    "    for s_idx, e_idx in intervals_idx:\n",
    "        s_ts = df.loc[s_idx, timestamp_col]\n",
    "        e_ts = df.loc[e_idx, timestamp_col]\n",
    "        intervals_ts.append((s_ts, e_ts))\n",
    "\n",
    "    context_window = 60\n",
    "    for i, (s_idx, e_idx) in enumerate(intervals_idx[:5]):\n",
    "        start_context = max(0, s_idx - context_window)\n",
    "        end_context = min(len(df) - 1, e_idx + context_window)\n",
    "\n",
    "        df_seg = df.loc[start_context : end_context].copy()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        sc = plt.scatter(\n",
    "            df_seg[timestamp_col],\n",
    "            df_seg[speed_col],\n",
    "            c=df_seg[label_col],\n",
    "            cmap='coolwarm',\n",
    "            s=15,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "\n",
    "        s_ts = df.loc[s_idx, timestamp_col]\n",
    "        e_ts = df.loc[e_idx, timestamp_col]\n",
    "\n",
    "        plt.axvline(x=s_ts, color='green', linestyle='--', linewidth=1.2, label='Anomaly Start')\n",
    "        plt.axvline(x=e_ts, color='red', linestyle='--', linewidth=1.2, label='Anomaly End')\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Speed')\n",
    "        plt.title(f'Test Interval {i+1}: {s_ts} ‚Üí {e_ts}')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"{save_path_prefix}_test_interval_{i+1}.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot: {filename}\")\n",
    "\n",
    "    return intervals_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6210c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (80000, 36)\n",
      "Validation shape: (10000, 36)\n",
      "Test shape: (10000, 36)\n",
      "\n",
      "Anomaly distribution in training set:\n",
      "pred_label\n",
      "0    0.95695\n",
      "1    0.04305\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Anomaly distribution in validation set:\n",
      "pred_label\n",
      "0    0.9569\n",
      "1    0.0431\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Anomaly distribution in test set:\n",
      "pred_label\n",
      "0    0.957\n",
      "1    0.043\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Training XGBClassifier on TRAIN split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rupesh Kumar singh\\OneDrive\\Desktop\\Work\\AGC Work\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:03:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "\n",
      "--- MODEL EVALUATION ON VALIDATION SPLIT ---\n",
      "Accuracy (Val): 0.9998\n",
      "Balanced Accuracy (Val): 0.9977\n",
      "ROC AUC (Val): 1.0000\n",
      "\n",
      "Classification Report (Val):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9569\n",
      "           1       1.00      1.00      1.00       431\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Confusion Matrix (Val):\n",
      "[[9569    0]\n",
      " [   2  429]]\n",
      "\n",
      "\n",
      "--- FEATURE IMPORTANCES (XGBoost) ---\n",
      "                     Feature  Importance\n",
      "       Speed_rolling_std_300    0.474951\n",
      "        Speed_rolling_min_60    0.098253\n",
      "    Speed_rolling_median_300    0.076284\n",
      "    Speed_rolling_zscore_900    0.051370\n",
      "    Speed_ewm_mean_alpha_0.1    0.050463\n",
      "  Speed_mean_median_diff_300    0.041971\n",
      "       Speed_rolling_min_300    0.037774\n",
      "       Speed_rolling_mean_60    0.027805\n",
      "        Speed_rolling_q25_60    0.022048\n",
      "     Speed_ewm_std_alpha_0.1    0.017716\n",
      "      Speed_rolling_mean_900    0.013824\n",
      "Speed_positive_deviation_300    0.012563\n",
      "      Speed_rolling_mean_300    0.011034\n",
      "        Speed_rolling_std_60    0.009385\n",
      "       Speed_rolling_std_900    0.008397\n",
      "                Speed_diff_5    0.005849\n",
      "        Speed_rolling_q75_60    0.005771\n",
      "       Speed_rolling_q25_300    0.004721\n",
      "                 Speed_lag_1    0.004578\n",
      "   Speed_mean_median_diff_60    0.003542\n",
      "                Speed_diff_1    0.003491\n",
      "     Speed_cusum_positive_60    0.002360\n",
      "                       Speed    0.002100\n",
      "  Speed_mean_median_diff_900    0.002078\n",
      "          Speed_acceleration    0.001866\n",
      "    Speed_cusum_positive_300    0.001837\n",
      "     Speed_rolling_zscore_60    0.001410\n",
      "       Speed_rolling_q75_300    0.001329\n",
      "       Speed_rolling_max_300    0.001173\n",
      "    Speed_rolling_zscore_300    0.000906\n",
      "     Speed_rolling_median_60    0.000830\n",
      "        Speed_rolling_max_60    0.000797\n",
      "                Speed_lag_60    0.000718\n",
      "    Speed_rolling_median_900    0.000513\n",
      "              Speed_lag_3600    0.000248\n",
      " Speed_positive_deviation_60    0.000043\n",
      "\n",
      "\n",
      "Predicting on TEST split and plotting anomaly intervals...\n",
      "2024-09-03 23:21:23+07:00 2024-09-03 23:21:23+07:00\n",
      "Saved plot: anomaly_interval_test_interval_1.png\n",
      "2024-09-06 08:18:25+07:00 2024-09-06 08:18:25+07:00\n",
      "Saved plot: anomaly_interval_test_interval_2.png\n",
      "2024-09-14 20:45:57+07:00 2024-09-14 20:45:57+07:00\n",
      "Saved plot: anomaly_interval_test_interval_3.png\n",
      "2024-09-03 23:18:10+07:00 2024-09-03 23:18:10+07:00\n",
      "Saved plot: anomaly_interval_test_interval_4.png\n",
      "2024-09-14 17:30:49+07:00 2024-09-14 17:30:49+07:00\n",
      "Saved plot: anomaly_interval_test_interval_5.png\n",
      "\n",
      "Final Result: Found 413 anomaly ranges on TEST split.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = 'AGC_Data.csv'\n",
    "    try:\n",
    "        data_df = pd.read_csv(file_path, parse_dates=['indo_time'])\n",
    "        intervals_ts = detect_anomaly_range_ml(\n",
    "            df=data_df,\n",
    "            speed_col='speed',\n",
    "            label_col='pred_label',\n",
    "            timestamp_col='indo_time',\n",
    "            random_state=42,\n",
    "            save_path_prefix='anomaly_interval'\n",
    "        )\n",
    "\n",
    "        if intervals_ts:\n",
    "            print(f\"\\nFinal Result: Found {len(intervals_ts)} anomaly ranges on TEST split.\")\n",
    "        else:\n",
    "            print(\"\\nFinal Result: No anomaly ranges found on TEST split.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1f4f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes ‚Üí  Train: (60000, 36),  Val: (20000, 36),  Test: (20000, 36)\n",
      "\n",
      "Anomaly distribution in TRAIN: {0: 0.95695, 1: 0.04305}\n",
      "Anomaly distribution in VALID: {0: 0.95695, 1: 0.04305}\n",
      "Anomaly distribution in TEST:  {0: 0.95695, 1: 0.04305}\n",
      "\n",
      "\n",
      "Training XGBClassifier on TRAIN split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rupesh Kumar singh\\OneDrive\\Desktop\\Work\\AGC Work\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "\n",
      "--- MODEL EVALUATION ON VALIDATION SPLIT ---\n",
      "Accuracy (Val): 0.9997\n",
      "Balanced Accuracy (Val): 0.9982\n",
      "ROC AUC (Val): 1.0000\n",
      "\n",
      "Classification Report (Val):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19139\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "Confusion Matrix (Val):\n",
      "[[19136     3]\n",
      " [    3   858]]\n",
      "\n",
      "\n",
      "--- FEATURE IMPORTANCES (XGBoost) ---\n",
      "                     Feature  Importance\n",
      "       Speed_rolling_std_300    0.519172\n",
      "    Speed_ewm_mean_alpha_0.1    0.171661\n",
      "    Speed_rolling_median_300    0.070850\n",
      "  Speed_mean_median_diff_300    0.039620\n",
      "        Speed_rolling_min_60    0.033039\n",
      "       Speed_rolling_min_300    0.028034\n",
      "        Speed_rolling_std_60    0.020926\n",
      "        Speed_rolling_q75_60    0.017053\n",
      "      Speed_rolling_mean_300    0.016170\n",
      "        Speed_rolling_q25_60    0.012541\n",
      "       Speed_rolling_mean_60    0.010637\n",
      "     Speed_ewm_std_alpha_0.1    0.008083\n",
      "       Speed_rolling_std_900    0.007132\n",
      "       Speed_rolling_q75_300    0.006491\n",
      "      Speed_rolling_mean_900    0.005165\n",
      "       Speed_rolling_q25_300    0.004699\n",
      "          Speed_acceleration    0.002801\n",
      "       Speed_rolling_max_300    0.002750\n",
      "     Speed_cusum_positive_60    0.002698\n",
      "  Speed_mean_median_diff_900    0.002461\n",
      "                Speed_diff_1    0.002375\n",
      "    Speed_rolling_zscore_300    0.002262\n",
      " Speed_positive_deviation_60    0.002003\n",
      "     Speed_rolling_zscore_60    0.001898\n",
      "Speed_positive_deviation_300    0.001714\n",
      "   Speed_mean_median_diff_60    0.001451\n",
      "    Speed_rolling_median_900    0.001371\n",
      "    Speed_rolling_zscore_900    0.001241\n",
      "                       Speed    0.000914\n",
      "     Speed_rolling_median_60    0.000584\n",
      "                 Speed_lag_5    0.000537\n",
      "        Speed_rolling_max_60    0.000505\n",
      "                Speed_diff_5    0.000416\n",
      "    Speed_cusum_positive_300    0.000301\n",
      "                 Speed_lag_1    0.000283\n",
      "                Speed_lag_60    0.000163\n",
      "\n",
      "\n",
      "Predicting on TEST split and plotting anomaly intervals‚Ä¶\n",
      "Saved plot: anomaly_interval_test_interval_1.png\n",
      "Saved plot: anomaly_interval_test_interval_2.png\n",
      "Saved plot: anomaly_interval_test_interval_3.png\n",
      "Saved plot: anomaly_interval_test_interval_4.png\n",
      "Saved plot: anomaly_interval_test_interval_5.png\n",
      "\n",
      "Final Result: Found 12 anomaly ranges on TEST split.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_anomaly_range_ml(\n",
    "    df,\n",
    "    speed_col='speed',\n",
    "    label_col='pred_label',\n",
    "    timestamp_col='indo_time',\n",
    "    random_state=42,\n",
    "    save_path_prefix='anomaly_interval'\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Builds rolling / lagged features on `speed_col`.\n",
    "    2) Splits data into 60% train / 20% validation / 20% test via two train_test_split calls.\n",
    "    3) Trains XGBClassifier on the 60% TRAIN split.\n",
    "    4) Evaluates on the 20% VALIDATION split.\n",
    "    5) Predicts on the 20% TEST split, then sorts by original index so that\n",
    "       contiguous original‚Äêindex anomalies are grouped correctly. Finally,\n",
    "       plots up to 5 anomaly intervals (with a ¬±60‚Äêsample context) from the test set.\n",
    "    \"\"\"\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    # 1) BUILD FEATURE‚ÄêENGINEERING DATAFRAME\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    features = pd.DataFrame(df[speed_col]).copy()\n",
    "    features.columns = ['Speed']\n",
    "\n",
    "    window_short = 60\n",
    "    window_medium = 300\n",
    "    window_long = 900\n",
    "\n",
    "    # Rolling‚Äêwindow means + stds\n",
    "    features[f'Speed_rolling_mean_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "    features[f'Speed_rolling_std_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_mean_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .mean()\n",
    "    )\n",
    "    features[f'Speed_rolling_std_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_mean_{window_long}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_long, min_periods=int(window_long * 0.2))\n",
    "        .mean()\n",
    "    )\n",
    "    features[f'Speed_rolling_std_{window_long}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_long, min_periods=int(window_long * 0.2))\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # 1a) Temporal‚Äêtransition features\n",
    "    features['Speed_diff_1'] = df[speed_col].diff(periods=1).fillna(0)\n",
    "    features['Speed_diff_5'] = df[speed_col].diff(periods=5).fillna(0)\n",
    "    features['Speed_acceleration'] = df[speed_col].diff(periods=1).diff(periods=1).fillna(0)\n",
    "\n",
    "    # 1b) Rolling‚Äêzscore\n",
    "    features[f'Speed_rolling_zscore_{window_short}'] = (\n",
    "        (df[speed_col] - features[f'Speed_rolling_mean_{window_short}']) /\n",
    "        (features[f'Speed_rolling_std_{window_short}'] + 1e-9)\n",
    "    )\n",
    "    features[f'Speed_rolling_zscore_{window_medium}'] = (\n",
    "        (df[speed_col] - features[f'Speed_rolling_mean_{window_medium}']) /\n",
    "        (features[f'Speed_rolling_std_{window_medium}'] + 1e-9)\n",
    "    )\n",
    "    features[f'Speed_rolling_zscore_{window_long}'] = (\n",
    "        (df[speed_col] - features[f'Speed_rolling_mean_{window_long}']) /\n",
    "        (features[f'Speed_rolling_std_{window_long}'] + 1e-9)\n",
    "    )\n",
    "\n",
    "    # 1c) Rolling‚Äêmedian + mean‚Äêmedian difference\n",
    "    features[f'Speed_rolling_median_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .median()\n",
    "    )\n",
    "    features[f'Speed_mean_median_diff_{window_short}'] = (\n",
    "        features[f'Speed_rolling_mean_{window_short}'] -\n",
    "        features[f'Speed_rolling_median_{window_short}']\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_median_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .median()\n",
    "    )\n",
    "    features[f'Speed_mean_median_diff_{window_medium}'] = (\n",
    "        features[f'Speed_rolling_mean_{window_medium}'] -\n",
    "        features[f'Speed_rolling_median_{window_medium}']\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_median_{window_long}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_long, min_periods=int(window_long * 0.2))\n",
    "        .median()\n",
    "    )\n",
    "    features[f'Speed_mean_median_diff_{window_long}'] = (\n",
    "        features[f'Speed_rolling_mean_{window_long}'] -\n",
    "        features[f'Speed_rolling_median_{window_long}']\n",
    "    )\n",
    "\n",
    "    # 1d) CUSUM of positive deviations\n",
    "    features[f'Speed_positive_deviation_{window_short}'] = np.maximum(\n",
    "        0, df[speed_col] - features[f'Speed_rolling_mean_{window_short}']\n",
    "    )\n",
    "    features[f'Speed_cusum_positive_{window_short}'] = (\n",
    "        features[f'Speed_positive_deviation_{window_short}'].cumsum()\n",
    "    )\n",
    "\n",
    "    features[f'Speed_positive_deviation_{window_medium}'] = np.maximum(\n",
    "        0, df[speed_col] - features[f'Speed_rolling_mean_{window_medium}']\n",
    "    )\n",
    "    features[f'Speed_cusum_positive_{window_medium}'] = (\n",
    "        features[f'Speed_positive_deviation_{window_medium}'].cumsum()\n",
    "    )\n",
    "\n",
    "    # 1e) Additional rolling stats (min, max, quartiles)\n",
    "    features[f'Speed_rolling_min_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .min()\n",
    "    )\n",
    "    features[f'Speed_rolling_max_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .max()\n",
    "    )\n",
    "    features[f'Speed_rolling_q25_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .quantile(0.25)\n",
    "    )\n",
    "    features[f'Speed_rolling_q75_{window_short}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_short, min_periods=1)\n",
    "        .quantile(0.75)\n",
    "    )\n",
    "\n",
    "    features[f'Speed_rolling_min_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .min()\n",
    "    )\n",
    "    features[f'Speed_rolling_max_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .max()\n",
    "    )\n",
    "    features[f'Speed_rolling_q25_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .quantile(0.25)\n",
    "    )\n",
    "    features[f'Speed_rolling_q75_{window_medium}'] = (\n",
    "        df[speed_col]\n",
    "        .rolling(window=window_medium, min_periods=int(window_medium * 0.2))\n",
    "        .quantile(0.75)\n",
    "    )\n",
    "\n",
    "    # 1f) EWMA (alpha=0.1)\n",
    "    features['Speed_ewm_mean_alpha_0.1'] = (\n",
    "        df[speed_col]\n",
    "        .ewm(span=10, adjust=False, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "    features['Speed_ewm_std_alpha_0.1'] = (\n",
    "        df[speed_col]\n",
    "        .ewm(span=10, adjust=False, min_periods=1)\n",
    "        .std()\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # 1g) Lagged features\n",
    "    features['Speed_lag_1'] = df[speed_col].shift(1).fillna(0)\n",
    "    features['Speed_lag_5'] = df[speed_col].shift(5).fillna(0)\n",
    "    features['Speed_lag_60'] = df[speed_col].shift(60).fillna(0)\n",
    "\n",
    "    # Final X, y\n",
    "    X = features.fillna(features.mean())\n",
    "    y = df[label_col]\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    # 2) 60% / 20% / 20% SPLIT VIA train_test_split\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    #\n",
    "    # Step A: Split off 20% as TEST\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.20,             # 20% of entire dataset ‚Üí TEST\n",
    "        stratify=y,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Step B: From the remaining 80% (X_train_val), split off 25% of that\n",
    "    # ‚Üí which is 0.25 * 0.80 = 0.20 of the entire dataset ‚Üí VALIDATION.\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        test_size=0.25,             # 25% of TRAIN_VAL = 20% of total ‚Üí VALIDATION\n",
    "        stratify=y_train_val,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"Shapes ‚Üí  Train: {X_train.shape},  Val: {X_val.shape},  Test: {X_test.shape}\\n\")\n",
    "    print(\"Anomaly distribution in TRAIN:\",  y_train.value_counts(normalize=True).to_dict())\n",
    "    print(\"Anomaly distribution in VALID:\",  y_val.value_counts(normalize=True).to_dict())\n",
    "    print(\"Anomaly distribution in TEST: \",  y_test.value_counts(normalize=True).to_dict())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Compute scale_pos_weight (for imbalance) on TRAIN split\n",
    "    neg_count = y_train.value_counts().get(0, 0)\n",
    "    pos_count = y_train.value_counts().get(1, 0)\n",
    "    scale_pos_weight = (neg_count / pos_count) if (pos_count > 0) else 1\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    # 3) TRAIN XGBClassifier ON TRAIN SPLIT\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    print(\"Training XGBClassifier on TRAIN split...\")\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=random_state,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_pos_weight\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Training complete.\\n\")\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    # 4) EVALUATE ON VALIDATION SPLIT\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    print(\"--- MODEL EVALUATION ON VALIDATION SPLIT ---\")\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    print(f\"Accuracy (Val): {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "    print(f\"Balanced Accuracy (Val): {balanced_accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "    try:\n",
    "        print(f\"ROC AUC (Val): {roc_auc_score(y_val, y_val_proba):.4f}\")\n",
    "    except ValueError:\n",
    "        print(\"ROC AUC (Val): N/A (only one class present).\")\n",
    "\n",
    "    print(\"\\nClassification Report (Val):\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    print(\"Confusion Matrix (Val):\")\n",
    "    print(confusion_matrix(y_val, y_val_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Show feature importances\n",
    "    print(\"--- FEATURE IMPORTANCES (XGBoost) ---\")\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    print(feature_importances.to_string(index=False))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    # 5) PREDICT & PLOT ON TEST SPLIT\n",
    "    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "    print(\"Predicting on TEST split and plotting anomaly intervals‚Ä¶\")\n",
    "\n",
    "    # When we called train_test_split, X_test.index still refers to the original df indices.\n",
    "    # To get correct ‚Äúcontiguous in time‚Äù grouping, we must sort by that original index.\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_idx = X_test.index.values\n",
    "\n",
    "    # Build a small DataFrame of (orig_idx, pred_label), then sort by orig_idx:\n",
    "    test_df = pd.DataFrame({\n",
    "        'orig_idx': test_idx,\n",
    "        'pred': y_test_pred\n",
    "    })\n",
    "    test_df = test_df.sort_values(by='orig_idx').reset_index(drop=True)\n",
    "\n",
    "    # Now scan for runs where pred == 1\n",
    "    intervals_idx = []\n",
    "    in_anomaly = False\n",
    "    start_idx = None\n",
    "\n",
    "    for row in test_df.itertuples(index=False):\n",
    "        orig_i = row.orig_idx\n",
    "        label = row.pred\n",
    "\n",
    "        if (label == 1) and (not in_anomaly):\n",
    "            # start a new anomaly run\n",
    "            in_anomaly = True\n",
    "            start_idx = orig_i\n",
    "\n",
    "        elif (label == 0) and in_anomaly:\n",
    "            # close the anomaly run at the previous index\n",
    "            intervals_idx.append((start_idx, prev_i))\n",
    "            in_anomaly = False\n",
    "\n",
    "        prev_i = orig_i\n",
    "\n",
    "    # If we ended while still in an anomaly run, close it now:\n",
    "    if in_anomaly:\n",
    "        intervals_idx.append((start_idx, prev_i))\n",
    "\n",
    "    if not intervals_idx:\n",
    "        print(\"No predicted anomaly intervals in TEST split.\")\n",
    "        return []\n",
    "\n",
    "    # Convert each (start_idx, end_idx) to timestamps\n",
    "    intervals_ts = []\n",
    "    for (s_idx, e_idx) in intervals_idx:\n",
    "        s_ts = df.loc[s_idx, timestamp_col]\n",
    "        e_ts = df.loc[e_idx, timestamp_col]\n",
    "        intervals_ts.append((s_ts, e_ts))\n",
    "\n",
    "    # Plot up to FIRST 5 anomaly intervals (with ¬±60‚Äêsample context)\n",
    "    context_window = 60\n",
    "    for i, (s_idx, e_idx) in enumerate(intervals_idx[:5]):\n",
    "        start_context = max(0, s_idx - context_window)\n",
    "        end_context   = min(len(df) - 1, e_idx + context_window)\n",
    "\n",
    "        df_seg = df.loc[start_context : end_context].copy()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        sc = plt.scatter(\n",
    "            df_seg[timestamp_col],\n",
    "            df_seg[speed_col],\n",
    "            c=df_seg[label_col],\n",
    "            cmap='coolwarm',\n",
    "            s=15,\n",
    "            edgecolors='none'\n",
    "        )\n",
    "\n",
    "        s_ts = df.loc[s_idx, timestamp_col]\n",
    "        e_ts = df.loc[e_idx, timestamp_col]\n",
    "\n",
    "        plt.axvline(x=s_ts, color='green', linestyle='--', linewidth=1.2, label='Anomaly Start')\n",
    "        plt.axvline(x=e_ts, color='red', linestyle='--', linewidth=1.2, label='Anomaly End')\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Speed')\n",
    "        plt.title(f'Test Interval {i+1}: {s_ts} ‚Üí {e_ts}')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"{save_path_prefix}_test_interval_{i+1}.png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot: {filename}\")\n",
    "\n",
    "    return intervals_ts\n",
    "\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# USAGE EXAMPLE (if run as a script)\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'AGC_Data.csv'\n",
    "    try:\n",
    "        data_df = pd.read_csv(file_path, parse_dates=['indo_time'])\n",
    "        intervals_ts = detect_anomaly_range_ml(\n",
    "            df=data_df,\n",
    "            speed_col='speed',\n",
    "            label_col='pred_label',\n",
    "            timestamp_col='indo_time',\n",
    "            random_state=42,\n",
    "            save_path_prefix='anomaly_interval'\n",
    "        )\n",
    "\n",
    "        if intervals_ts:\n",
    "            print(f\"\\nFinal Result: Found {len(intervals_ts)} anomaly ranges on TEST split.\")\n",
    "        else:\n",
    "            print(\"\\nFinal Result: No anomaly ranges found on TEST split.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during execution: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbc69d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes ‚Üí  Train: (60000, 36),  Val: (20000, 36),  Test: (20000, 36)\n",
      "\n",
      "Anomaly distribution in TRAIN: {0: 0.95695, 1: 0.04305}\n",
      "Anomaly distribution in VALID: {0: 0.95695, 1: 0.04305}\n",
      "Anomaly distribution in TEST:  {0: 0.95695, 1: 0.04305}\n",
      "\n",
      "\n",
      "Training XGBClassifier on TRAIN split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rupesh Kumar singh\\OneDrive\\Desktop\\Work\\AGC Work\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "\n",
      "--- MODEL EVALUATION ON VALIDATION SPLIT ---\n",
      "Accuracy (Val): 0.9997\n",
      "Balanced Accuracy (Val): 0.9982\n",
      "ROC AUC (Val): 1.0000\n",
      "\n",
      "Classification Report (Val):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19139\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "Confusion Matrix (Val):\n",
      "[[19136     3]\n",
      " [    3   858]]\n",
      "\n",
      "\n",
      "--- FEATURE IMPORTANCES (XGBoost) ---\n",
      "                     Feature  Importance\n",
      "       Speed_rolling_std_300    0.519172\n",
      "    Speed_ewm_mean_alpha_0.1    0.171661\n",
      "    Speed_rolling_median_300    0.070850\n",
      "  Speed_mean_median_diff_300    0.039620\n",
      "        Speed_rolling_min_60    0.033039\n",
      "       Speed_rolling_min_300    0.028034\n",
      "        Speed_rolling_std_60    0.020926\n",
      "        Speed_rolling_q75_60    0.017053\n",
      "      Speed_rolling_mean_300    0.016170\n",
      "        Speed_rolling_q25_60    0.012541\n",
      "       Speed_rolling_mean_60    0.010637\n",
      "     Speed_ewm_std_alpha_0.1    0.008083\n",
      "       Speed_rolling_std_900    0.007132\n",
      "       Speed_rolling_q75_300    0.006491\n",
      "      Speed_rolling_mean_900    0.005165\n",
      "       Speed_rolling_q25_300    0.004699\n",
      "          Speed_acceleration    0.002801\n",
      "       Speed_rolling_max_300    0.002750\n",
      "     Speed_cusum_positive_60    0.002698\n",
      "  Speed_mean_median_diff_900    0.002461\n",
      "                Speed_diff_1    0.002375\n",
      "    Speed_rolling_zscore_300    0.002262\n",
      " Speed_positive_deviation_60    0.002003\n",
      "     Speed_rolling_zscore_60    0.001898\n",
      "Speed_positive_deviation_300    0.001714\n",
      "   Speed_mean_median_diff_60    0.001451\n",
      "    Speed_rolling_median_900    0.001371\n",
      "    Speed_rolling_zscore_900    0.001241\n",
      "                       Speed    0.000914\n",
      "     Speed_rolling_median_60    0.000584\n",
      "                 Speed_lag_5    0.000537\n",
      "        Speed_rolling_max_60    0.000505\n",
      "                Speed_diff_5    0.000416\n",
      "    Speed_cusum_positive_300    0.000301\n",
      "                 Speed_lag_1    0.000283\n",
      "                Speed_lag_60    0.000163\n",
      "\n",
      "\n",
      "Predicting on TEST split and plotting anomaly intervals‚Ä¶\n",
      "Saved plot: anomaly_interval_test_interval_1.png\n",
      "Saved plot: anomaly_interval_test_interval_2.png\n",
      "Saved plot: anomaly_interval_test_interval_3.png\n",
      "Saved plot: anomaly_interval_test_interval_4.png\n",
      "Saved plot: anomaly_interval_test_interval_5.png\n",
      "\n",
      "Final Result: Found 12 anomaly ranges on TEST split.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = 'AGC_Data.csv'\n",
    "    try:\n",
    "        data_df = pd.read_csv(file_path, parse_dates=['indo_time'])\n",
    "        intervals_ts = detect_anomaly_range_ml(\n",
    "            df=data_df,\n",
    "            speed_col='speed',\n",
    "            label_col='pred_label',\n",
    "            timestamp_col='indo_time',\n",
    "            random_state=42,\n",
    "            save_path_prefix='anomaly_interval'\n",
    "        )\n",
    "\n",
    "        if intervals_ts:\n",
    "            print(f\"\\nFinal Result: Found {len(intervals_ts)} anomaly ranges on TEST split.\")\n",
    "        else:\n",
    "            print(\"\\nFinal Result: No anomaly ranges found on TEST split.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7729e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
