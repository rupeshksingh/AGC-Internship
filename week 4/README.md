# Advanced Model Testing: CATCH, SPOT, VAE & XGBoost (Week 4)

This document details the work from the fourth week, which focused on evaluating another state-of-the-art research model, implementing an advanced thresholding technique, and establishing strong neural network and gradient boosting baselines for anomaly detection on the glass rolling dataset.

---

## üéØ Objective

The primary goal of this week was to continue the exploration of advanced models and techniques. The key objectives were:
1.  [cite_start]**Implement the CATCH Model**: To test the **CATCH (Channel-Aware multivariate Time series detection)** model, a recent research model, on the project's dataset[cite: 143].
2.  **Establish Baselines**: To use a **Variational Autoencoder (VAE)** and an **XGBoost Classifier** as strong baseline models for comparison.
3.  **Explore Dynamic Thresholding**: To implement the **Streaming Peaks-Over-Threshold (SPOT)** algorithm for setting a more robust and data-driven anomaly threshold.

---

## ‚öôÔ∏è Methodologies & Findings

### **1. CATCH Model Implementation**
[cite_start]The CATCH model, known for its novel frequency patching approach, was adapted and tested[cite: 144].

* **Methodology**:
    * [cite_start]The model's architecture, which leverages a frequency patching technique to achieve state-of-the-art performance, was applied to the roller speed data[cite: 144].
    * This required adapting the time series data to fit the model's expected input format and running inference to get anomaly scores.
* **Findings**:
    * [cite_start]The CATCH model demonstrated strong performance, achieving **84% accuracy**, which was a significant improvement over the initial baseline models[cite: 148].
    * The analysis notebook for DADA and CATCH provided a comparative look at the performance of these two research models on the dataset, highlighting their potential for industrial applications.

### **2. Variational Autoencoder (VAE) Baseline**
A VAE was implemented as an unsupervised deep learning baseline for anomaly detection.

* **Methodology**:
    * A VAE was constructed and trained to reconstruct the normal patterns of the time series data.
    * Anomalies were detected by identifying data points where the reconstruction error was high, indicating that the model struggled to reproduce them based on the learned normal behavior.
* **Findings**:
    * The VAE served as a robust baseline, providing a benchmark for what a deep generative model could achieve in terms of identifying deviations from normality.

### **3. XGBoost Baseline**
An XGBoost classifier was implemented as a powerful supervised baseline.

* **Methodology**:
    * Features were engineered from the time series data to capture various statistical and temporal properties.
    * An XGBoost model was trained on these features using the provided labels to classify each time point as either normal or an anomaly.
* **Findings**:
    * The XGBoost model provided a strong performance baseline for supervised learning, leveraging its gradient boosting framework to effectively learn from the engineered features.

### **4. SPOT for Dynamic Thresholding**
The SPOT (Streaming Peaks-Over-Threshold) algorithm was used to determine a dynamic threshold for anomaly scores.

* **Methodology**:
    * SPOT is an algorithm based on Extreme Value Theory that is well-suited for setting thresholds on streaming data.
    * It was applied to the anomaly scores generated by one of the models to find an optimal, non-arbitrary cutoff point for flagging anomalies.
* **Findings**:
    * SPOT provided a principled and adaptive way to set anomaly thresholds, which is a critical step in operationalizing an anomaly detection system and reducing false positives.