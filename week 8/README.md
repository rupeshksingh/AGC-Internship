# Dual Training Approach for Anomaly Detection (Week 8)

This document outlines the work from the eighth week, which involved implementing a novel dual training strategy. This approach uses two specialist models‚Äîone trained on anomaly-rich data and one trained only on normal data‚Äîto improve prediction accuracy.

---

## üéØ Objective

The goal for this week was to explore an advanced ensemble-like technique to overcome the challenges of class imbalance and subtle anomaly detection. The core objective was to build a more robust detection system by combining the strengths of two complementary models: one "anomaly expert" and one "normality expert."

---

## ‚öôÔ∏è Methodology

The dual training approach, implemented in the `risk.py` script, is based on the idea that two specialist models can outperform a single generalist model.

### 1. The Concept
A single model trained on the full, imbalanced dataset can sometimes be biased towards the majority (normal) class. The dual training approach addresses this by creating two distinct models:
* **Model 1: The Anomaly Expert**: This model was trained on a dataset containing a rich concentration of anomaly sequences. Its purpose is to become highly skilled at recognizing the specific patterns associated with glass breakage.
* **Model 2: The Normality Expert**: This model was trained exclusively on data from normal operations. Its job is to learn a precise signature of what "normal" looks like. Any deviation from this learned pattern is flagged as a potential anomaly.

### 2. Combined Prediction
[cite_start]The final anomaly prediction is generated by combining the outputs of both models using a **weighted probability**[cite: 222]. The logic is as follows:
* If a data point is a clear anomaly, both models will likely flag it with high probability.
* If a data point is a **subtle anomaly**, the "anomaly expert" might assign it a moderate probability. However, the "normality expert" will flag it with a high probability because it deviates from the strict definition of normal it has learned.
* The combined weighted score amplifies the signal from both models, leading to a more confident and accurate final prediction.

---

## üìà Key Findings & Learnings

This innovative approach led to a significant improvement in performance.

* [cite_start]**Improved Accuracy**: The dual training method achieved an impressive **91% accuracy**, demonstrating a clear improvement over previous single-model approaches[cite: 258, 263].
* [cite_start]**Reliance on Post-Processing**: While the raw predictions were strong, the model's best performance was achieved after applying **post-processing steps**, such as filling small gaps between detected anomaly sequences[cite: 224].
* [cite_start]**Complementary Strengths**: The experiment successfully validated the hypothesis that combining two specialist models provides a more robust solution[cite: 223]. The "normality expert" was particularly effective at identifying subtle deviations that the more generalized models might have missed. This approach served as the strongest baseline before moving to the final, end-to-end TCNN architecture.